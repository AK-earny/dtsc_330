# Introduction to Machine Learning

![Machine Learning Diagram](ml_diagram.png)

Machine learning refers to the process of training a system to recognize patterns in data so it can make predictions. The pipeline of machine learning goes somewhat like this. You first split your given dataset into a training set and a testing set. The training set will be used to teach the model, while the testing set will be used to evaluates how well the model works on fresh data. For machine learning to work well, the training data must be large enough and representative of real-world situations. Additionally, before training, the data must be organized into features and labels. Features are the inputs of an algorithim and are typically measurable properties of the data (age, temperature, etc). The label is the value or output we want to predict. Speaking of predict, now we get to choose what kind of prediction model we want to use: logistic regression, decision trees, random forests, or XGBoost. If you want interperatablity, decision trees and logistic regression models are open box, meaning their decisions are easy to understand. If you're more concerned with accuracy however, random forests and XGBoost models are considered black box, meaning they are more complex but often achieve stronger performance. Choosing a model depends on the dataset, the problem being solved, and whether interpretability or accuracy is more important. At this point machine learning problems usually fall into two categories: classification vs regression. Classification predicts categories, while regression predicts numerical values. The type of label determines which approach should be used. During training, the model learns parameters, while hyperparameters control how learning happens. Good feature selection, clean data, and choosing an appropriate model all contribute to better performance. Finally, the testing set is used to evaluate the trained model and measure how well it generalizes to new data. This step ensures the model is learning real patterns rather than memorizing the training data.